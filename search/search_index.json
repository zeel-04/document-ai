{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Document AI","text":"<p>A library for parsing, formatting, and processing documents that can be used to build AI-powered document processing pipelines.</p> <p>Please refer to the quickstart for a guide on how to get started.</p>"},{"location":"quickstart/","title":"Quickstart","text":"<p>This guide will help you get started with Document AI.</p>"},{"location":"quickstart/#installation","title":"Installation","text":""},{"location":"quickstart/#requirements","title":"Requirements","text":"<ul> <li>Python &gt;= 3.10</li> <li>OpenAI API key</li> </ul>"},{"location":"quickstart/#install-uv","title":"Install uv","text":"<p>First, install uv if you haven't already:</p> <pre><code>curl -LsSf https://astral.sh/uv/install.sh | sh\n</code></pre>"},{"location":"quickstart/#install-from-source","title":"Install from Source","text":"<p>Clone the repository and install the package:</p> <pre><code># Clone the repository\ngit clone https://github.com/zeel-04/document-ai.git\ncd document-ai\n\n# Install the package with uv\nuv sync\n</code></pre>"},{"location":"quickstart/#install-from-git-alternative","title":"Install from Git (Alternative)","text":"<p>You can also install directly from the git repository:</p> <pre><code>uv pip install git+https://github.com/zeel-04/document-ai.git\n</code></pre>"},{"location":"quickstart/#environment-setup","title":"Environment Setup","text":"<p>Document AI uses OpenAI's API for document processing. Set up your API key:</p> <pre><code># Create a .env file\necho \"OPENAI_API_KEY=your-api-key-here\" &gt; .env\n</code></pre>"},{"location":"quickstart/#basic-usage","title":"Basic Usage","text":"<p>Here's a simple example to extract structured data from a PDF document:</p> <pre><code>from dotenv import load_dotenv\nfrom document_ai.processer import DocumentProcessor\nfrom document_ai.llm import OpenAILLM\nfrom pydantic import BaseModel\n\n# Load environment variables\nload_dotenv()\n\n# Initialize the LLM\nllm = OpenAILLM()\n\n# Create a processor from a PDF file\nprocessor = DocumentProcessor.from_pdf(\n    uri=\"path/to/your/document.pdf\",\n    llm=llm,\n)\n\n# Define your data model with citations\n# If you want to include citations for any field, \n# you can do so by adding the suffix `_citation` to the field name and using the `processor.citation_type` as the type.\nclass EndingBalance(BaseModel):\n    ending_balance: float\n    ending_balance_citation: processor.citation_type\n    start_balance: float\n    start_balance_citation: processor.citation_type\n\n# Extract structured data\nresponse = processor.extract(\n    model=\"gpt-5-mini\",\n    reasoning={\"effort\": \"low\"},\n    response_format=EndingBalance,\n)\n\n# Get the extracted data\ndata = response.model_dump()\nprint(data)\n</code></pre>"},{"location":"quickstart/#sample-output","title":"Sample Output","text":"<pre><code>{\n    \"ending_balance\": 111.61,\n    \"ending_balance_citation\": [{\n        \"page\": 0,\n        \"lines\": [18],\n        \"bboxes\": [{\n            \"x0\": 0.058823529411764705,\n            \"top\": 0.6095707475757575,\n            \"x1\": 0.5635455037254902,\n            \"bottom\": 0.6221969596969696\n        }]\n    }],\n    \"start_balance\": 610.52,\n    \"start_balance_citation\": [{\n        \"page\": 0,\n        \"lines\": [13],\n        \"bboxes\": [{\n            \"x0\": 0.078823529411764705,\n            \"top\": 0.49401637363636364,\n            \"x1\": 0.5639691831372549,\n            \"bottom\": 0.5060113736363636\n        }]\n    }]\n}\n</code></pre>"}]}